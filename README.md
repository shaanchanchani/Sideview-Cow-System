# Side-view Cow Feature Extraction System 

This repository hosts an adaptable, library-based implementation of a video analytics system for Cows. It implements He Liu's
post-processing procedure for side-view cow feature extraction. A detailed discussion of this procedure can be found linked here:

[A cow structural model for video analytics of cow health](https://arxiv.org/abs/2003.05903)

The motivation for this overhaul stems from these features having demonstrated success in body weight estimation.

## Installation
Clone this repo, and run
```
conda create -n moo python=3.8.18 
conda activate moo
pip install "deeplabcut[tf]"==2.3.8
```

## Usage

The only function necessary to run the system end-to-end is `run_sideview_system()`.

This function requires the following parameters to be specfied:

1) `input_video_folders`: A list of folder names containing your test videos. These folders should be at the same directory level as the library.

2) `output_folder` : Directory to store analysis results. Output video can be found in `merge_res` sub-folder of this directory.

3) `cow_model_key`: String specifyig which CNN set and cow model to use.

The following keys are supported for `cow_model_key`:

- `channel_3` : the original structural model with DLC CNNs Liu trained using data from just the IP camera. The snapshots for these DLC models are located in `cow_v3rgb-20191008` and `cow_v3diff-20191008`.

- `merge` : the original structural model with DLC CNNs Liu trained using data from all three cameras (IP, DVR, GoPro). The snapshots for these DLC models are located in `cow_3_data_v3-He-2019-10-08` and `cow_3_data_dif_v3-He-2019-10-08`. 

- `merge_underbelly` : structural model with an underbelly point with DLC CNNs I trained using data from all three cameras (IP, DVR, GoPro). The snapshots for these DLC models are located in `cow_3_data_v4-Underbelly-Shaan-2023-11-24` and `cow_3_data_dif_v4-Underbelly-Shaan-2023-11-24`.

## System Breakdown

### 1. `__init__.py`

This is the entry point of the system, where the `run_sideview_system()` function is defined. This function begins by initializing a configuration object using the provided `cow_model_key`. This configuration object stores critical information needed throughout the system, so it is passed along.

Another notable function in this file is `run_on_video()`. It runs the entire system pipeline on a single video. `run_sideview_system()` works by calling `run_on_video()` with the original video for every video in the input folder, and then calls `run_on_video()` again for every frame difference version of each video. The actual merging of predictions happens in `pp_parts_from_two_nets_npy`.

### 2. `config.py`

This file contains code for initializing the cow model. Modifying the system to support another cow model should only require adding the modifying this file. The `Config` class has the following attributes:

- `model_set`: Initialized with the `cow_model_key` passed by `run_sideview_system()`. It ensures the correct body part lists, limb connections, and training data for the cow centroid model are used.
- `cow_centroid_model_data`: Initialized using the `cow_model_key`. It stores the path to a CSV file containing labels to generate the cow centroid model. The actual cow centroid model is generated once this is stored.

The following attributes are hard-coded based on the `cow_model_key`:

- `body_region_points`: List of parts included in the cow's body region.
- `head_region_points`: List of points located on the head.
- `leg_region_points`: List of points located on the legs.
- `body_limbs`: Nested list displaying how the body region points are connected.
- `leg_limbs`: Nested list displaying how the leg region points are connected.

Once all data fields are initialized, the actual cow centroid model is generated by importing the `generate_cow_centroid_model` function from `cow_centroid_model.py`.

### 3. `body_region_part_extraction.py`

This file contains the code described in section 3.4.1 of He's paper.

### 4. `cow_clustering.py`

This file contains the code described in the first three paragraphs of section 3.4.2 of He's paper.

### 5. `leg_region_part_extraction.py`

This file contains the code described in the final paragraph of section 3.4.2 of He's paper.

### 6. `temporal_filtering.py`

This file contains the code described in section 3.4.3 of He's paper.

## Editing DLC Models

These were the steps taken to modify He's DeepLabCut (DLC) model. In hindsight, this may not have been the easiest way to do this, but these were the steps followed.

1. Download GUI support for DLC with this command:
```
pip install --upgrade "deeplabcut[gui,tf]==2.3.8"
```
2. Make a copy of the project directory of the DLC model you want to modify.
3. Update the `project_path` parameter in the `config.yaml` file.
4. Add the new body part you want to label at the end of the `bodyparts` list in `config.yaml`.
5. Delete everything except the `labeled-data` folder, `videos` folder, and `config.yaml`. The deleted files will need to be regenerated after modifying the labels.
6. Open a Python terminal and import `deeplabcut`.
7. Run `deeplabcut.launch_dlc()` and navigate to the "Label Frames" tab on the DLC GUI. Click the "Label Frames" button to launch the Napari GUI.
8. You'll notice that the new body part you want to label appears in the left-hand side color scheme list but is missing from the keypoint selection list on the right. To get the new body part to appear in the keypoint selection list, drag and drop the `config.yaml` file over the GUI.
9. From here, you can follow DLC's documentation to regenerate the `training-datasets` and `dlc-models` folders.

For reference, these lines were used to train and evaluate the underbelly models:

```python
python deeplabcut.create_training_dataset('/home/schancha/cow_models/cow_3_data_v4-Shaan-2023-09-30/config.yaml', net_type='resnet_50', augmenter_type='imgaug')
deeplabcut.train_network('/home/schancha/cow_models/cow_3_data_v4-Shaan-2023-09-30/config.yaml', gputouse=0, allow_growth=True)
deeplabcut.evaluate_network('./config.yaml')
```

## Misc. tips:
- The Nature Protocols paper has a lot more information than DeepLabCut's documentation on github. It is linked here:
https://www.nature.com/articles/s41593-018-0209-y

- If you encounter an error that says something along the lines of "ValueError: The passed save_path is not a valid checkpoint..." It is because the ResNet50 default weights did not get downloaded. The following link explains how to fix this:
https://github.com/DeepLabCut/DeepLabCut/issues/276
